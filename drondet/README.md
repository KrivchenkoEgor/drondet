# DroneDet - Система детекции дронов по звуку

## Описание проекта

**DroneDet** - это система машинного обучения для обнаружения дронов по аудио сигналам в реальном времени. Проект использует сверточные нейронные сети (CNN) для анализа Mel-спектрограмм аудио сигналов и классификации их на два класса: "дрон" или "фон".

## ⚠️ Важное замечание

**Модель обучается ТОЛЬКО на реальных данных!** Для обучения необходимо подготовить реальные аудио файлы с дронами и фоновыми звуками.

## Архитектура проекта

### Структура директорий

```
drondet/
├── scripts/              # Основные скрипты проекта
│   ├── audio_utils.py    # Утилиты для работы с аудио
│   ├── drone_detector.py # Класс детектора дронов (CNN модель)
│   ├── train.py          # Скрипт для обучения модели с нуля
│   ├── retrain.py        # Скрипт для дообучения модели на пользовательских данных
│   └── detect_realtime.py # Скрипт для детекции в реальном времени
├── models/               # Сохраненные модели
│   ├── drone_detector.h5 # Основная обученная модель
│   └── drone_detector_scaler.pkl # Scaler для нормализации данных
├── data/                 # Данные для обучения
│   ├── raw/              # Исходные аудио файлы
│   ├── processed/        # Обработанные данные
│   └── user_samples/     # Пользовательские данные для дообучения
├── audio_samples/        # Примеры аудио файлов
├── alerts/               # Звуки тревоги
└── notebooks/            # Jupyter notebooks для анализа
```

## Технологический стек

- **Python 3.10+**
- **TensorFlow/Keras** - нейронные сети
- **librosa** - обработка аудио сигналов
- **NumPy** - численные вычисления
- **scikit-learn** - предобработка данных (StandardScaler)
- **sounddevice** - запись и воспроизведение аудио в реальном времени
- **pydub** - конвертация аудио форматов (требует ffmpeg)
- **matplotlib** - визуализация

## Основные компоненты

### 1. `audio_utils.py` - Утилиты для работы с аудио

**Назначение**: Обработка аудио файлов, извлечение признаков, автоматическая конвертация форматов.

**Основные функции**:
- `load_audio()` - загрузка аудио файлов (поддержка wav, m4a, mp3, flac, ogg, aac, wma и др.)
- `extract_features()` - извлечение Mel-спектрограмм (64×44)
- `convert_m4a_to_wav()` - конвертация m4a в wav (требует ffmpeg)
- `save_alert_sound()` - создание звука тревоги

**Параметры**:
- Частота дискретизации: 22050 Hz
- Размер Mel-спектрограммы: 64×44
- Длина сегмента: 1 секунда

### 2. `drone_detector.py` - Класс детектора дронов

**Назначение**: Реализация CNN модели для классификации аудио сигналов.

**Архитектура модели**:
```
Input: (64, 44, 1) - Mel-спектрограмма
├── Conv2D(32) + BatchNorm + MaxPool + Dropout(0.2)
├── Conv2D(64) + BatchNorm + MaxPool + Dropout(0.3)
├── Conv2D(128) + BatchNorm + MaxPool + Dropout(0.4)
├── Flatten
├── Dense(128) + BatchNorm + Dropout(0.5)
├── Dense(64)
└── Dense(1, sigmoid) - Бинарная классификация
```

**Основные методы**:
- `build_model()` - создание архитектуры CNN
- `train()` - обучение модели на данных
- `predict()` - предсказание наличия дрона в аудио сегменте
- `load_model()` - загрузка предобученной модели и scaler
- `preprocess_data()` - предобработка данных (нормализация через StandardScaler)

**Важные детали**:
- Использует StandardScaler для нормализации данных
- Scaler сохраняется отдельно в `.pkl` файле
- Порог детекции по умолчанию: 0.7
- Поддерживает работу без scaler (использует альтернативную нормализацию)

### 3. `train.py` - Обучение модели с нуля

**Назначение**: Обучение модели на **реальных данных** из директории `data/raw/`.

**⚠️ ВАЖНО**: Модель обучается только на реальных аудио файлах.

**Процесс**:
1. Собирает реальные аудио файлы из `data/raw/`
2. Автоматически определяет метки по именам файлов:
   - Файлы с "drone" в имени → метка "дрон" (1)
   - Файлы с "background"/"noise"/"ambient" → метка "фон" (0)
3. Разбивает файлы на сегменты по 1 секунде
4. Разделяет данные на train/val (80/20)
5. Обучает CNN модель (30 эпох, batch_size=16)
6. Сохраняет модель и scaler
7. Выводит метрики: accuracy, precision, recall

**Требования к данным**:
- Файлы должны быть в директории `data/raw/`
- Имена файлов должны содержать ключевые слова для определения меток
- Поддерживаемые форматы: .wav, .m4a, .mp3, .flac
- Рекомендуется иметь баланс классов (примерно 50/50)

**Использование**:
```bash
PYTHONPATH=/path/to/drondet python scripts/train.py
```

**Пример структуры данных**:
```
data/raw/
├── drone_sample1.mp3
├── drone_sample2.wav
├── background_noise1.wav
└── ambient_sound.mp3
```

### 4. `retrain.py` - Дообучение модели

**Назначение**: Дообучение существующей модели на пользовательских данных.

**Процесс**:
1. Собирает аудио файлы из `data/user_samples/`
2. **Все файлы автоматически считаются звуками дрона** (метка "дрон" = 1)
3. Поддерживает любые аудио форматы (wav, mp3, m4a, flac, ogg, aac, wma и др.)
4. Автоматически конвертирует файлы при необходимости
5. При дисбалансе классов (только дроны) автоматически генерирует синтетические фоновые данные для баланса
6. Выполняет fine-tuning (замораживает все слои кроме последних 4)
7. Использует меньший learning rate (0.0001)
8. Заменяет основную модель, если accuracy > 0.7

**Использование**:
```bash
PYTHONPATH=/path/to/drondet python scripts/retrain.py
```

**Требования к файлам**:
- Любые аудио форматы (автоматическая конвертация)
- Все файлы в `data/user_samples/` считаются звуками дрона
- Размещать в `data/user_samples/`

### 5. `detect_realtime.py` - Детекция в реальном времени

**Назначение**: Детекция дронов в реальном времени с микрофона или анализ аудио файлов.

**Режимы работы**:
1. **realtime** - запись с микрофона в реальном времени
2. **file** - анализ аудио файла

**Функции**:
- `detect_realtime()` - детекция с микрофона
- `detect_from_file()` - анализ файла
- `play_alert_sound()` - воспроизведение звука тревоги

**Использование**:
```bash
# Реальное время
PYTHONPATH=/path/to/drondet python scripts/detect_realtime.py --mode realtime

# Анализ файла
PYTHONPATH=/path/to/drondet python scripts/detect_realtime.py --mode file --file audio_samples/flying-drone.mp3

# С параметрами
python scripts/detect_realtime.py --mode realtime --threshold 0.8 --duration 2.0 --no-alert
```

**Параметры**:
- `--mode`: realtime или file
- `--file`: путь к аудио файлу (для режима file)
- `--model`: путь к модели (по умолчанию models/drone_detector.h5)
- `--threshold`: порог вероятности для детекции (по умолчанию 0.7)
- `--duration`: длительность сегмента в секундах (для realtime, по умолчанию 1.0)
- `--no-alert`: отключить звуковое оповещение

## Установка и настройка

### Требования

**Python пакеты**:
```bash
pip install tensorflow librosa soundfile numpy scikit-learn matplotlib joblib
pip install pydub sounddevice  # опционально
```

**Системные зависимости (macOS)**:
```bash
brew install ffmpeg  # для конвертации m4a файлов
```

**Разрешения (macOS)**:
- Разрешить доступ к микрофону в Системных настройках → Безопасность → Конфиденциальность → Микрофон

### Настройка окружения

1. Создать виртуальное окружение:
```bash
python -m venv .venv
source .venv/bin/activate  # macOS/Linux
```

2. Установить зависимости:
```bash
pip install -r requirements.txt  # если есть
# или вручную установить пакеты из списка выше
```

3. Установить PYTHONPATH (или использовать в командах):
```bash
export PYTHONPATH=/path/to/drondet:$PYTHONPATH
```

## Рабочий процесс

### 1. Первичное обучение модели

```bash
PYTHONPATH=/path/to/drondet python scripts/train.py
```

Результат:
- `models/drone_detector.h5` - обученная модель
- `models/drone_detector_scaler.pkl` - scaler для нормализации

### 2. Дообучение на реальных данных

1. Поместить аудио файлы в `data/user_samples/`:
   - Файлы с дронами: имена должны содержать "drone"
   - Фоновые файлы: имена должны содержать "background", "noise" или "ambient"

2. Запустить дообучение:
```bash
PYTHONPATH=/path/to/drondet python scripts/retrain.py
```

### 3. Использование для детекции

**Реальное время**:
```bash
PYTHONPATH=/path/to/drondet python scripts/detect_realtime.py --mode realtime
```

**Анализ файла**:
```bash
PYTHONPATH=/path/to/drondet python scripts/detect_realtime.py --mode file --file path/to/audio.mp3
```

## Формат данных

### Входные данные
- **Формат**: Mel-спектрограммы размером 64×44×1
- **Частота дискретизации**: 22050 Hz
- **Длина сегмента**: 1 секунда
- **Нормализация**: StandardScaler (обучается на train данных)

### Выходные данные
- **Вероятность**: float от 0 до 1
- **Класс**: bool (True если вероятность > threshold, по умолчанию 0.7)

## Особенности реализации

### Обработка отсутствующего scaler
Если scaler не найден при загрузке модели, используется альтернативная нормализация:
```python
mel_spec = mel_spec / (np.max(np.abs(mel_spec)) + 1e-8)
```

### Автоматическая генерация фоновых данных
При дообучении, если обнаружен дисбаланс классов (только дроны, без фоновых), автоматически генерируются синтетические фоновые данные для баланса.

### Кроссплатформенность
- Все пути используют `os.path.join()` для совместимости с macOS/Linux/Windows
- Абсолютные пути определяются через `os.path.abspath(__file__)`

### Обработка зависимостей
- Проверка наличия `pydub` и `sounddevice` с понятными сообщениями об ошибках
- Graceful degradation при отсутствии опциональных зависимостей

## Метрики и производительность

### Типичные результаты обучения
- **Точность после дообучения**: 65-80% (зависит от качества данных)
- **Время обучения**: ~1-2 минуты на 500 образцов (M1 Mac)
- **Время предсказания**: ~50-100ms на сегмент

### Оптимизация
- Использование Metal (GPU) на Apple Silicon
- Batch processing для эффективной обработки
- Early stopping для предотвращения переобучения

## Известные ограничения

1. **Требуются реальные данные**: Модель обучается только на реальных аудио файлах. Необходимо подготовить достаточное количество данных для обучения.
2. **Баланс классов**: Рекомендуется иметь примерно равное количество примеров дронов и фоновых звуков.
3. **Зависимость от scaler**: Для корректной работы требуется обученный scaler
4. **Порог детекции**: Фиксированный порог 0.7 может требовать настройки под конкретные условия
5. **Формат аудио**: Для конвертации m4a требуется ffmpeg




